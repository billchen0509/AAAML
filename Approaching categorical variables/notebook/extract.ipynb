{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'Freezing': 0,\n",
    "    'Warm': 1,\n",
    "    'Cold': 2,\n",
    "    'Boiling Hot': 3,\n",
    "    'Hot': 4,\n",
    "    'Lava Hot': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../input/cat_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Freezing       142726\n",
       "Warm           124239\n",
       "Cold            97822\n",
       "Boiling Hot     84790\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69001/1730110582.py:1: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, 'ord_2'] = df.ord_2.map(mapping)\n"
     ]
    }
   ],
   "source": [
    "df.loc[:, 'ord_2'] = df.ord_2.map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    142726\n",
       "1.0    124239\n",
       "2.0     97822\n",
       "3.0     84790\n",
       "4.0     67508\n",
       "5.0     64840\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69001/2139754939.py:14: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, 'ord_2'] = lbl_enc.transform(df.ord_2)\n"
     ]
    }
   ],
   "source": [
    "# Lable Encoding, i.e., converting each category to a number\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df = pd.read_csv('../input/cat_train.csv')\n",
    "# fill NaN values in ord_2 column\n",
    "df.loc[:, 'ord_2'] = df.ord_2.fillna('NONE')\n",
    "\n",
    "# initialize LabelEncoder\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "\n",
    "# fit label encoder and transform values on ord_2 column\n",
    "# fit first and then transform\n",
    "lbl_enc.fit(df.ord_2)\n",
    "df.loc[:, 'ord_2'] = lbl_enc.transform(df.ord_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    142726\n",
       "6    124239\n",
       "1     97822\n",
       "0     84790\n",
       "3     67508\n",
       "4     64840\n",
       "5     18075\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tree-based models, we can directly use:\n",
    "- Decision trees\n",
    "- Random forest\n",
    "- Extra trees\n",
    "- OR any kind of boosted trees model:\n",
    "    - XGBoost\n",
    "    - GBM\n",
    "    - LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of encoding cannot be used in linear models, support vector machines or neural networks as they expect data to be normalized (or standardized).\n",
    "\n",
    "For these types of models, we can $\\textbf{binarize}$ the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "example = np.array(\n",
    "    [\n",
    "        [0,0,1],\n",
    "        [1,0,0],\n",
    "        [1,0,1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# print size in bytes\n",
    "print(example.nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sparse format is a representation of only storing valuable data in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "example = np.array(\n",
    "    [\n",
    "        [0,0,1],\n",
    "        [1,0,0],\n",
    "        [1,0,1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "sparse = sparse.csr_matrix(example)\n",
    "\n",
    "print(sparse.data.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "print(sparse.data.nbytes + sparse.indptr.nbytes + sparse.indices.nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in size becomes vast when we have much larger arrays, letâ€™s say with thousands of samples and tens of thousands of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dense array: 8000000000\n",
      "Size of sparse array: 399948688\n",
      "Full size of sparse array: 599963036\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "n_rows = 10000\n",
    "n_cols = 100000\n",
    "\n",
    "example = np.random.binomial(1, p=0.05, size=(n_rows, n_cols))\n",
    "print(f\"Size of dense array: {example.nbytes}\")\n",
    "\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "print(f\"Size of sparse array: {sparse_example.data.nbytes}\")\n",
    "\n",
    "full_size = (\n",
    "    sparse_example.data.nbytes + \n",
    "    sparse_example.indptr.nbytes + \n",
    "    sparse_example.indices.nbytes\n",
    ")\n",
    "print(f\"Full size of sparse array: {full_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encoding: a binary encoding too in the sense that there are only two values, 0s and 1s. This is not a binary representation.\n",
    "\n",
    "The vector size has to be same as number of categories we are looking at.\n",
    "\n",
    "Each vector has a 1 and rest all other values are 0s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of dense array: 120\n",
      "size of sparse array: 24\n",
      "full size of sparse array: 52\n"
     ]
    }
   ],
   "source": [
    "example = np.array([\n",
    "    [0, 0, 0, 0, 1],\n",
    "    [0, 1, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 0]\n",
    "])\n",
    "\n",
    "print(f'size of dense array: {example.nbytes}')\n",
    "\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "print(f'size of sparse array: {sparse_example.data.nbytes}')\n",
    "\n",
    "full_size = (\n",
    "    sparse_example.data.nbytes +\n",
    "    sparse_example.indptr.nbytes +\n",
    "    sparse_example.indices.nbytes\n",
    ")\n",
    "print(f'full size of sparse array: {full_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billhikari/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/billhikari/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dense array: 800000\n",
      "Size of sparse array: 800000\n",
      "Full size of sparse array: 1600004\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn import preprocessing\n",
    "\n",
    "example = np.random.randint(1000, size=100000)\n",
    "\n",
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "ohe_example = ohe.fit_transform(example.reshape(-1, 1))\n",
    "\n",
    "print(f\"Size of dense array: {example.nbytes}\")\n",
    "\n",
    "ohe = preprocessing.OneHotEncoder(sparse=True)\n",
    "ohe_example = ohe.fit_transform(example.reshape(-1, 1))\n",
    "\n",
    "print(f\"Size of sparse array: {ohe_example.data.nbytes}\")\n",
    "\n",
    "full_size = (\n",
    "    ohe_example.data.nbytes +\n",
    "    ohe_example.indptr.nbytes +\n",
    "    ohe_example.indices.nbytes\n",
    ")\n",
    "print(f\"Full size of sparse array: {full_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84790, 25)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../input/cat_train.csv')\n",
    "df[df.ord_2 == 'Boiling Hot'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ord_2\n",
       "Boiling Hot     84790\n",
       "Cold            97822\n",
       "Freezing       142726\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "Warm           124239\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['ord_2'])['id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          67508.0\n",
       "1         124239.0\n",
       "2         142726.0\n",
       "3          64840.0\n",
       "4          97822.0\n",
       "            ...   \n",
       "599995    142726.0\n",
       "599996     84790.0\n",
       "599997    142726.0\n",
       "599998    124239.0\n",
       "599999     84790.0\n",
       "Name: id, Length: 600000, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['ord_2'])[\"id\"].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 Contributor_Hot\n",
       "1                Grandmaster_Warm\n",
       "2                    nan_Freezing\n",
       "3                 Novice_Lava Hot\n",
       "4                Grandmaster_Cold\n",
       "                   ...           \n",
       "599995            Novice_Freezing\n",
       "599996         Novice_Boiling Hot\n",
       "599997       Contributor_Freezing\n",
       "599998                Master_Warm\n",
       "599999    Contributor_Boiling Hot\n",
       "Name: new_feature, Length: 600000, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['new_feature'] = (\n",
    "    df.ord_1.astype(str) + '_' + df.ord_2.astype(str)\n",
    ")\n",
    "df.new_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "Whenver you got categorical variables, follow these steps:\n",
    "- fill the NaN values !!!\n",
    "- convert them to integers by applying label encoding using LableEncoder of scikit-learn or by using a mapping dictionary.\n",
    "- create on-hot encoding.\n",
    "- go for modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Freezing       142726\n",
       "Warm           124239\n",
       "Cold            97822\n",
       "Boiling Hot     84790\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "NONE            18075\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_2.fillna('NONE').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
      "/var/folders/ff/tm9v3zh91jv9vg9vgbf1rhnr0000gn/T/ipykernel_69401/3276007242.py:28: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "train = pd.read_csv('../input/cat_train.csv')\n",
    "\n",
    "test = pd.read_csv('../input/cat_test.csv')\n",
    "\n",
    "# create a fake target column for test data\n",
    "# since this column doesn't exist\n",
    "test.loc[:, 'target'] = -1\n",
    "\n",
    "# concatenate both training and test data\n",
    "data = pd.concat([train, test]).reset_index(drop=True)\n",
    "\n",
    "# make a list of features we are interested in\n",
    "# id and target is something we should not encode\n",
    "features = [x for x in train.columns if x not in ['id', 'target']]\n",
    "\n",
    "# loop over the features list\n",
    "for feat in features:\n",
    "    lbl_enc = preprocessing.LabelEncoder()\n",
    "    # note the trick here\n",
    "    # since its categorical data, we fillna with a string\n",
    "    # and we convert all the data to string type\n",
    "    # so, no matter its int or float, its converted to string\n",
    "    # int/float but categorical!!!\n",
    "    temp_col = data[feat].fillna('NONE').astype(str).values\n",
    "    data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
    "\n",
    "# split the training and test data again\n",
    "train = data[data.target != -1].reset_index(drop=True)\n",
    "test = data[data.target == -1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N       39978\n",
       "P       37890\n",
       "Y       36657\n",
       "A       36633\n",
       "R       33045\n",
       "U       32897\n",
       "M       32504\n",
       "X       32347\n",
       "C       32112\n",
       "H       31189\n",
       "Q       30145\n",
       "T       29723\n",
       "O       25610\n",
       "B       25212\n",
       "E       21871\n",
       "K       21676\n",
       "I       19805\n",
       "NONE    17930\n",
       "D       17284\n",
       "F       16721\n",
       "W        8268\n",
       "Z        5790\n",
       "S        4595\n",
       "G        3404\n",
       "V        3107\n",
       "J        1950\n",
       "L        1657\n",
       "Name: ord_4, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_4.fillna('NONE').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N       39978\n",
       "P       37890\n",
       "Y       36657\n",
       "A       36633\n",
       "R       33045\n",
       "U       32897\n",
       "M       32504\n",
       "X       32347\n",
       "C       32112\n",
       "H       31189\n",
       "Q       30145\n",
       "T       29723\n",
       "O       25610\n",
       "B       25212\n",
       "E       21871\n",
       "K       21676\n",
       "I       19805\n",
       "NONE    17930\n",
       "D       17284\n",
       "F       16721\n",
       "W        8268\n",
       "Z        5790\n",
       "S        4595\n",
       "RARE     3607\n",
       "G        3404\n",
       "V        3107\n",
       "Name: ord_4, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_4 = df.ord_4.fillna('NONE')\n",
    "df.loc[df['ord_4'].value_counts()[df['ord_4']].values < 2000, 'ord_4'] = 'RARE'\n",
    "df.ord_4.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    120000\n",
       "1    120000\n",
       "2    120000\n",
       "3    120000\n",
       "4    120000\n",
       "Name: kfold, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../input/cat_train_folds.csv')\n",
    "\n",
    "df.kfold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    97535\n",
      "1    22465\n",
      "Name: target, dtype: int64\n",
      "0    97535\n",
      "1    22465\n",
      "Name: target, dtype: int64\n",
      "0    97535\n",
      "1    22465\n",
      "Name: target, dtype: int64\n",
      "0    97536\n",
      "1    22464\n",
      "Name: target, dtype: int64\n",
      "0    97536\n",
      "1    22464\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check the target distribution \n",
    "print(df[df.kfold == 0].target.value_counts())\n",
    "print(df[df.kfold == 1].target.value_counts())\n",
    "print(df[df.kfold == 2].target.value_counts())\n",
    "print(df[df.kfold == 3].target.value_counts())\n",
    "print(df[df.kfold == 4].target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
